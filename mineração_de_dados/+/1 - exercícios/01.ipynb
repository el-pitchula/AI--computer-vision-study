{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orientações:\n",
    "\n",
    "Os alunos que forem pegos colando da prova de outro colega, ou passando cola, terão a nota imediatamente zerada para II. O mesmo segue para quem for pego utilizando o CHAT GPT ou o Google.\n",
    "\n",
    "A prova pode ser realizada com consultas e anotações de outras aulas, no cadernos, arquivos de resumo...\n",
    "\n",
    "`Não esqueçam de colocar o nome e o RA na célula de código abaixo!!!`\n",
    "\n",
    "Após a conclusão da prova, enviar o arquivo para o e-mail arthur.siqueira@ceub.edu.br\n",
    "\n",
    "O nome do arquivo deve ser mantido como \"prova.ipynb\" e o nome e RA escritos a baixo serão utilizados para saber de quem é cada prova.\n",
    "\n",
    "OBS: Todos os comandos input deverão possuir um texto informando o que se deseja que digite. Em casos que forem possíveis, personalize o texto do input com informações do usuário.\n",
    "\n",
    "EX: Crie uma variável idade e utilize o input para solicitar o nome -> O código seria \"idade = int(input('Digite a idade'))\"\n",
    "\n",
    "A prova possui 10 questões, sendo 4 fáceis, 3 medianas e 3 relativamente difíceis.\n",
    "\n",
    "O import das bibliotecas necessárias pode ficar no topo do código ou conforme for utilizando as bibliotecas. Fica a critério de cada um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Gabriel Assis de Paula\r\n",
    "# RA: 22201568"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Realize a leitura e análise da base de dados notebooks.csv\n",
    "\n",
    "`METADADOS` da base de dados (Informações a respeito da base de dados)\n",
    "Esta é uma base de dados com informações de notebooks vendidos no brasil de 2010 a 2023 e possuí as seguintes colunas:\n",
    "\n",
    "marca, ano, qtd_nucleos, qtd_threads, ram, gpu_dedicada, ram_gpu, entradas_usb, duracao_bateria, resolucao_tela, tipo_tela, tela_touch, armazenamento_hdd, armazenamento_ssd, segmento, valor.\n",
    "\n",
    "A coluna marca pode conter os valores: samsung, hp, dell, lenovo, acer, asus, apple, razer, xiaomi, huawei ou positivo.\n",
    "\n",
    "A coluna ano possui o ano de lançamento do notebook.\n",
    "\n",
    "A coluna qtd_nucleos corresponte à quantidade de núclues de processamento que a CPU do notebook possui.\n",
    "\n",
    "A coluna qtd_threads refere à quantidade de threads que o processador possuí.\n",
    "\n",
    "A coluna ram representa quantos gb de memória RAM o notebook possuí, e pode ser de 2, 4, 6, 8, 12, 16, 32 ou 64.\n",
    "\n",
    "A coluna gpu_dedicada representa se o notebook possui ou não uma placa de vídeo dedicada.\n",
    "\n",
    "A coluna ram_gpu representa quantos gb de memória RAM o notebook possuí na placa de vídeo dedicada. Se o notebook não possuir placa de vídeo dedicada (valor \"não\" na coluna gpu_dedicada), o valor nesta coluna é 0.\n",
    "\n",
    "A coluna entradas_usb representa quantas entradas USB o notebook possui e os valores podem ser 1, 2, 3, 4 ou 5.\n",
    "\n",
    "A coluna duracao_bateria refere-se à quantos minutos o notebook dura na bateria fora da tomada.\n",
    "\n",
    "A coluna resolucao_tela refere-se à resolução de tela do notebook, podendo ser HD, FULHD, QUADHD ou 4K, em ordem respectiva da tecnologia mais barata para a mais cara.\n",
    "\n",
    "A coluna tipo_tela refere-se ao tipo de tela do notebook, com os possíveis valores sendo TN, IPS, VA, OLED ou AMOLED, em ordem respectiva da tecnologia mais barata para a mais cara.\n",
    "\n",
    "A coluna tela_touch representa se o notebook possui a tela Touchscreen ou não.\n",
    "\n",
    "A coluna armazenamento_hdd representa quantos gb de armazenamento o notebook possui em HDD, podendo ser valores de 250, 500, 1000 ou 2000 (se o notebook não tiver HDD, o valor nesta coluna é 0).\n",
    "\n",
    "A coluna armazenamento_ssd representa quantos gb de armazenamento o notebook possui em SSD, podendo ser valores de 125, 250, 500, 1000 ou 2000 (se o notebook não tiver SSD, o valor nesta coluna é 0).\n",
    "\n",
    "A coluna segmento representa qual segmento o notebook possui, podendo ser entrada, intermediario, premium, 2em1, jogos_entrada, jogos_intermediarios, jogos_premium, ultraportatil.\n",
    "\n",
    "A coluna valor possui o valor de lançamento do notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca \"pandas\" com o apelido \"pd\" para manipulação de dados\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando o csv como dataframe com um comando pandas\r\n",
    "df = pd.read_csv('notebooks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando as 5 primeiras linhas do dataframe para ter uma noção básica da tabela\r\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o tipo de cada coluna do dataframe e mais algumas informações úteis, como quantidade de linhas e colunas\r\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o dataframe possui 50000 linhas e 16 colunas\r\n",
    "# o tipo da coluna ser \"int64\" indica que é uma coluna numérica sem casas decimais, há 10 colunas desse tipo\r\n",
    "# o tipo da coluna ser \"object\" indica que é uma coluna textual, há 6 colunas desse tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando métricas estatísticas de cada coluna numérica (colunas do tipo \"int64\")\r\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"count\" é a quantidade de itens da coluna no dataframe no total (todos tem o mesmo valor, a tabela está completamente preenchida nas colunas de valores numéricos)\r\n",
    "# \"mean\" é a média aritmética da coluna\r\n",
    "# \"std\" é o desvio padrão dentro da coluna\r\n",
    "# \"min\" é o menor valor da coluna\r\n",
    "# \"25%\" é o quartil de 25% da coluna, ou seja, o valor exato que é maior do que os 25% menores valores da coluna e apenas maior do que esses 25%\r\n",
    "# \"50%\" é o quartil de 50% da coluna, ou seja, o valor exato que é maior do que os 50% menores valores da coluna e apenas maior do que esses 50% (esse valor também é a mediana da coluna)\r\n",
    "# \"75%\" é o quartil de 75% da coluna, ou seja, o valor exato que é maior do que os 75% menores valores da coluna e apenas maior do que esses 75%\r\n",
    "# \"max\" é o maior valor da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando algumas métricas estatísticas de cada coluna não-numérica (colunas do tipo \"object\")\r\n",
    "df.describe(include = \"object\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"count\" é a quantidade de itens da coluna no dataframe no total (todos tem o mesmo valor, a tabela está completamente preenchida nas colunas de valores não-numéricos)\r\n",
    "# \"unique\" é a quantidade de itens únicos na coluna (a quantidade de valores possíveis para cada coluna)\r\n",
    "# \"top\" é o item que aparece mais vezes na coluna\r\n",
    "# \"freq\" é a quantidade de vezes que o item mais comum aparece na coluna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Realize todo o tratamento de dados necessário para aplicar os dados em um algorítmo de rede neural para fazer uma regressão para prever o valor do notebook.\n",
    "\n",
    "- Tratar valores núlos (se houver);\n",
    "\n",
    "- Converter valores textuais para numéricos (como a rede neural faz cálculos, talvez seja mais interessante usar o loc para definir algumas colunas como a segmento, tipo tela... colocando valores numéricos mais intuitivos em relação ao valor, ou seja, o que é mais barato substitui por 0 e assim por diante. Se quiser usar apenas o label encoder não tem problema, mas pode obter resultados menos interessantes...);\n",
    "\n",
    "- Normalizar os dados;\n",
    "\n",
    "- Separar 0.2% para teste ( não é 20% nem 2%, é 0.2% mesmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando quantos valores nulos há em cada coluna\r\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# não há nenhum valor nulo em nenhuma coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo valores textuais para numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando mais uma vez quais colunas possui valores textuais, dessa vez com um comando mais compacto\r\n",
    "df.select_dtypes(include = 'object').columns\r\n",
    "\r\n",
    "# o comando \".select_dtypes\" retorna o tipo de cada coluna\r\n",
    "# o parametro \"include = 'object'\" define que serão retornadas apenas colunas de tipo \"object\", ou seja, textuais\r\n",
    "# o comando \".columns\" retorna apenas o tipo de cada coluna e mais nada do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma variável com os nomes de cada coluna\r\n",
    "colunas_texto = df.select_dtypes(include = 'object').columns.tolist()\r\n",
    "\r\n",
    "# o comando \".tolist()\" faz com que a variável seja uma lista (mais fácil de manipular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# são as colunas \"marca\", \"gpu_dedicada\", \"resolucao_tela\", \"tipo_tela\", \"tela_touch\", \"segmento\"\r\n",
    "# (algumas dessas colunas possuem valores binários de \"sim\" e \"não\", o que poderiam ser previamente registrados como 1 e 0, para facilitar a análise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando comando que faz a conversão automaticamente da biblioteca \"sci-kit learn\"\r\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando variável para o comando \"LabelEncoder()\"\r\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um loop na lista de colunas textuais que aplica o comando \"LabelEncoder()\" (a variável \"le\") para cada item na lista e substitui esse valor no dataframe original\r\n",
    "for coluna in colunas_texto:\r\n",
    "    df[coluna] = le.fit_transform(df[coluna])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando novamente os tipos de cada coluna do dataframe\r\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nenhuma coluna do tipo \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atribuindo todas as colunas do dataframe exceto a coluna alvo para a variável \"X\"\r\n",
    "X = df.drop('valor', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando se deu certo comparando o \"X\" com o dataframe normal\r\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando o \"X\"\r\n",
    "# importando comando de normalização de dados da biblioteca \"sci-kit learn\"\r\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma variável para o comando \"MinMaxScaler()\"\r\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando o comando \"MinMaxScaler()\" (a variável \"scaler\") para a variável \"X\"\r\n",
    "scaler.fit(X)\r\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atribuindo a coluna alvo do dataframe para a variável \"y\"\r\n",
    "y = df[['valor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando se deu certo comparando o \"y\" com o dataframe normal\r\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando o \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando outra variável para o comando \"MinMaxScaler()\"\r\n",
    "scaler_features = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando o comando \"MinMaxScaler()\" (a variável \"scaler\") para a variável \"y\"\r\n",
    "scaler_features.fit(y)\r\n",
    "y = scaler_features.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"y\" normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados para teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando comando para separar teste e treino da biblioteca \"sci-kit learn\"\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando em:\r\n",
    "# \"X\" de treino, \"X_train\";\r\n",
    "# \"X\" de teste, \"X_test\";\r\n",
    "# \"y\" de treino, \"y_train\" e\r\n",
    "# \"y\" de teste, \"y_test\"\r\n",
    "# com o comando \"train_test_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.002, random_state = 20)\r\n",
    "\r\n",
    "# o parametro \"test_size=\" define a separação de teste e treino para 0.2% (o valor deve ser inserido como número inteiro, ou seja, 0.2 dividido por 100)\r\n",
    "# (o parâmetro \"random_state=\" pode ser qualquer número, ele define uma seed para a aleatoriedade do modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2 / 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Treinamento de uma rede neural para regressão\n",
    "\n",
    "- Defina uma rede neural para realizar a regressão e prever o valor do notebook. A estrutura da rede neural fica a critério de cada um para definir quantas camadas ocultas e quantos neurônios nas camadas ocultas;\n",
    "\n",
    "- Defina 30% dos dados para validação (no treinamento, validation_split = 0.3)\n",
    "\n",
    "- Salve o histórico do treinamento em uma variável chamada history;\n",
    "\n",
    "- Para não demorar, não treine a rede por mais de 100 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando comandos de rede neural para regressão da biblioteca \"keras\", um módulo do \"tensorflow\"\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando variável \"model\" (porque é o modelo que será usado) para o comando \"Sequential()\"\r\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando a rede neural\r\n",
    "model.add(InputLayer(input_shape = (X_train.shape[1],)))\r\n",
    "model.add(Dense(64, activation = 'relu'))\r\n",
    "model.add(Dense(64, activation = 'relu'))\r\n",
    "model.add(Dense(64, activation = 'relu'))\r\n",
    "model.add(Dense(64, activation = 'relu'))\r\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na camada de entrada (primeira), o parametro \"input_shape=\" define a quantidade de atributos da camada de entrada\r\n",
    "# no caso, \"X_train.shape[1]\" (a quantidade de colunas da variavel X)\r\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nas camadas ocultas (da segunda à penúltima), definimos 64 neuronios por camada\r\n",
    "# e a função de ativação \"relu\", utilizada por padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na camada de saída (última), possui apenas 1 neurônio e\r\n",
    "# a função de ativação \"linear\", por ser uma regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando comando de erro médio quadrático da biblioteca \"sci-kit learn\"\r\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilando o modelo\r\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando o modelo na variável \"history\" para salvar seu histórico com 30% dos dados para validação\r\n",
    "history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.3)\r\n",
    "\r\n",
    "predict_rn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo treinado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - A) Exiba o erro médio quadrático (MSE)\n",
    "\n",
    "Para isto, faça uma previsão nos dados de X_test com o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desnormalizando \"y_test\" na variável \"y_test_desnormalizado\"\r\n",
    "y_test_desnormalizado = scaler_features.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desnormalizando \"predict_rn\" na variável \"predict_desnormalizado\"\r\n",
    "predict_desnormalizado = scaler_features.inverse_transform(predict_rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test_desnormalizado, predict_desnormalizado)\r\n",
    "print(\"Erro médio quadrático da regressão linear:\", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - B) Exiba um gráfico com os valores reais e preditos pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas de graficos\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_x = [x for x in range(1, len(y_test_desnormalizado)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grafico_x, y_test_desnormalizado, label = 'Real')\r\n",
    "plt.plot(grafico_x, predict_desnormalizado, label = 'Predito')\r\n",
    "\r\n",
    "plt.title('Valores reais e preditos pelo modelo')\r\n",
    "\r\n",
    "plt.legend()\r\n",
    "\r\n",
    "plt.ylabel('Valor')\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Faça um gráfico com o loss de treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_[['loss', 'val_loss']]).set(xlabel = 'Épocas', ylabel = 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Faça a leitura da base de dados notebooks_nulo.csv, trate os dados (valores nulos, textuais, normalização, transformar os valores de y em categoricos....) e separe em X e y de treinamento e teste com 20% para teste\n",
    "\n",
    "A base de dados notebooks_nulo.csv é semelhante à base de dados notebooks.csv, mas não possui a coluna valor e possui alguns valores nulos.\n",
    "\n",
    "Para separar os dados em X e y, considere a coluna segmento para ser o alvo (valor de y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('notebooks_nulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isna().sum() * 100 / len(df), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['marca'].isna()), 'marca'] = df['marca'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isna().sum() * 100 / len(df), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ano'].isna()), 'ano'] = df['ano'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isna().sum() * 100 / len(df), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['duracao_bateria'].isna()), 'duracao_bateria'] = df['duracao_bateria'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isna().sum() * 100 / len(df), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('tela_touch', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isna().sum() * 100 / len(df), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_texto = df.select_dtypes(include = 'object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in colunas_texto:\r\n",
    "    df[coluna] = le.fit_transform(df[coluna])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ano'] = df['ano'].astype(int)\r\n",
    "df['duracao_bateria'] = df['duracao_bateria'].astype(int)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('segmento', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)\r\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['segmento']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Treinamento de uma rede neural para classificação\n",
    "\n",
    "- Defina uma rede neural para realizar a classificação e prever qual o segmento do notebook. A estrutura da rede neural fica a critério de cada um para definir quantas camadas ocultas e quantos neurônios nas camadas ocultas;\n",
    "\n",
    "- Defina 15% dos dados para validação (no treinamento, validation_split = 0.15)\n",
    "\n",
    "- Salve o histórico do treinamento em uma variável chamada history;\n",
    "\n",
    "- Para não demorar, não treine a rede por mais de 100 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(16, activation = 'relu', input_shape = (X_train.shape[1],)))\r\n",
    "model.add(Dense(32, activation = 'relu'))\r\n",
    "model.add(Dense(32, activation = 'relu'))\r\n",
    "model.add(Dense(32, activation = 'relu'))\r\n",
    "model.add(Dense(16, activation = 'relu'))\r\n",
    "model.add(Dense(8, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Exiba a acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acurácia: {:.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Exiba a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\r\n",
    "y_pred = np.argmax(y_pred, axis = 1)\r\n",
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\r\n",
    "plt.title('Matriz de Confusão')\r\n",
    "plt.xlabel('Previsões')\r\n",
    "plt.ylabel('Real')\r\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Exiba um gráfico com os dados do treinamento.\n",
    "- loss;\n",
    "- val_loss;\n",
    "- accuracy;\n",
    "- val_accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df0[['loss', 'val_loss']]).set(xlabel = 'Epochs', ylabel = 'Loss')\r\n",
    "sns.lineplot(data = df0[['accuracy', 'val_accuracy']]).set(xlabel = 'Epochs', ylabel = 'Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('ProgramData': virtualenv)",
   "name": "python3913jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}