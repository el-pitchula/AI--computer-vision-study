{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Business Intelligence (BI) e Ciclo Analítico de Inteligência de Dados\n",
    "\n",
    "O BI é uma estratégia focada na análise de dados corporativos e na apresentação de informações acionáveis para ajudar os executivos, gerentes e outros usuários finais corporativos a tomar decisões de negócios informadas. O ciclo analítico de inteligência de dados é um processo que inclui várias etapas, desde a definição do problema até a comunicação dos resultados.\n",
    "\n",
    "## Importância do BI e do Ciclo Analítico de Inteligência de Dados\n",
    "\n",
    "Ambos são fundamentais para transformar dados brutos em insights significativos que podem impulsionar o sucesso do negócio. As organizações usam BI e análise de dados para identificar e resolver problemas, melhorar a eficiência, aumentar a produtividade e obter uma vantagem competitiva.\n",
    "\n",
    "*Exemplos reais:*\n",
    "1. Empresas de varejo utilizam BI para otimizar a cadeia de suprimentos, gerenciar inventário e melhorar a experiência do cliente.\n",
    "2. O setor de saúde usa análise de dados para melhorar o atendimento ao paciente, prever surtos de doenças e melhorar a eficiência operacional.\n",
    "\n",
    "\n",
    "# 2 - Fases do Projeto de BI\n",
    "\n",
    "Um projeto de BI normalmente passa pelas seguintes fases:\n",
    "\n",
    "1. **Estratégia de BI:** Definição dos objetivos e metas do projeto. Identificação das necessidades e expectativas dos usuários finais.\n",
    "\n",
    "2. **Análise de Requisitos:** Coleta e análise detalhada dos requisitos do usuário. Identificação das fontes de dados necessárias.\n",
    "\n",
    "3. **Design da Solução:** Design do data warehouse, esquema de dados, ETL, relatórios e painéis.\n",
    "\n",
    "4. **Implementação:** Desenvolvimento e teste do sistema de BI. Importação e transformação dos dados. Configuração dos relatórios e dashboards.\n",
    "\n",
    "5. **Entrega:** Lançamento do sistema de BI para os usuários finais. Treinamento e suporte.\n",
    "\n",
    "6. **Manutenção:** Monitoramento e atualização do sistema conforme necessário. Resolução de problemas e melhorias contínuas.\n",
    "\n",
    "Vamos explorar cada fase com mais detalhes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. Estratégia de BI\n",
    "# Definição dos objetivos: Vamos tentar prever a quantidade vendida com base nas outras características do conjunto de dados.\n",
    "\n",
    "# 2. Análise de Requisitos\n",
    "# Identificamos que precisamos das informações de quantidade vendida e das outras características como requisitos para nosso modelo.\n",
    "\n",
    "# 3. Design da Solução\n",
    "# Nosso data warehouse será o próprio dataframe do pandas. Vamos usar um modelo de regressão linear para prever a quantidade vendida.\n",
    "\n",
    "# 4. Implementação\n",
    "# Carregando os dados\n",
    "df = pd.read_csv('superstore_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Row ID</th>\n      <th>Order ID</th>\n      <th>Order Date</th>\n      <th>Ship Date</th>\n      <th>Ship Mode</th>\n      <th>Customer ID</th>\n      <th>Customer Name</th>\n      <th>Segment</th>\n      <th>City</th>\n      <th>State</th>\n      <th>...</th>\n      <th>Product ID</th>\n      <th>Category</th>\n      <th>Sub-Category</th>\n      <th>Product Name</th>\n      <th>Sales</th>\n      <th>Quantity</th>\n      <th>Discount</th>\n      <th>Profit</th>\n      <th>Shipping Cost</th>\n      <th>Order Priority</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42433</td>\n      <td>AG-2011-2040</td>\n      <td>1/1/2011</td>\n      <td>6/1/2011</td>\n      <td>Standard Class</td>\n      <td>TB-11280</td>\n      <td>Toby Braunhardt</td>\n      <td>Consumer</td>\n      <td>Constantine</td>\n      <td>Constantine</td>\n      <td>...</td>\n      <td>OFF-TEN-10000025</td>\n      <td>Office Supplies</td>\n      <td>Storage</td>\n      <td>Tenex Lockers, Blue</td>\n      <td>408.3</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>106.14</td>\n      <td>35.46</td>\n      <td>Medium</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 24 columns</p>\n</div>",
      "text/plain": "   Row ID      Order ID Order Date Ship Date       Ship Mode Customer ID   \n0   42433  AG-2011-2040   1/1/2011  6/1/2011  Standard Class    TB-11280  \\\n\n     Customer Name   Segment         City        State  ...        Product ID   \n0  Toby Braunhardt  Consumer  Constantine  Constantine  ...  OFF-TEN-10000025  \\\n\n          Category Sub-Category         Product Name  Sales Quantity Discount   \n0  Office Supplies      Storage  Tenex Lockers, Blue  408.3        2      0.0  \\\n\n   Profit  Shipping Cost  Order Priority  \n0  106.14          35.46          Medium  \n\n[1 rows x 24 columns]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51290 entries, 0 to 51289\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Row ID          51290 non-null  int64  \n",
      " 1   Order ID        51290 non-null  object \n",
      " 2   Order Date      51290 non-null  object \n",
      " 3   Ship Date       51290 non-null  object \n",
      " 4   Ship Mode       51290 non-null  object \n",
      " 5   Customer ID     51290 non-null  object \n",
      " 6   Customer Name   51290 non-null  object \n",
      " 7   Segment         51290 non-null  object \n",
      " 8   City            51290 non-null  object \n",
      " 9   State           51290 non-null  object \n",
      " 10  Country         51290 non-null  object \n",
      " 11  Postal Code     9994 non-null   float64\n",
      " 12  Market          51290 non-null  object \n",
      " 13  Region          51290 non-null  object \n",
      " 14  Product ID      51290 non-null  object \n",
      " 15  Category        51290 non-null  object \n",
      " 16  Sub-Category    51290 non-null  object \n",
      " 17  Product Name    51290 non-null  object \n",
      " 18  Sales           51290 non-null  float64\n",
      " 19  Quantity        51290 non-null  int64  \n",
      " 20  Discount        51290 non-null  float64\n",
      " 21  Profit          51290 non-null  float64\n",
      " 22  Shipping Cost   51290 non-null  float64\n",
      " 23  Order Priority  51290 non-null  object \n",
      "dtypes: float64(5), int64(2), object(17)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Row ID</th>\n      <th>Postal Code</th>\n      <th>Sales</th>\n      <th>Quantity</th>\n      <th>Discount</th>\n      <th>Profit</th>\n      <th>Shipping Cost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>51290.00000</td>\n      <td>9994.000000</td>\n      <td>51290.000000</td>\n      <td>51290.000000</td>\n      <td>51290.000000</td>\n      <td>51290.000000</td>\n      <td>51290.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>25645.50000</td>\n      <td>55190.379428</td>\n      <td>246.490581</td>\n      <td>3.476545</td>\n      <td>0.142908</td>\n      <td>28.610982</td>\n      <td>26.375915</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14806.29199</td>\n      <td>32063.693350</td>\n      <td>487.565361</td>\n      <td>2.278766</td>\n      <td>0.212280</td>\n      <td>174.340972</td>\n      <td>57.296804</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>1040.000000</td>\n      <td>0.444000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>-6599.978000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>12823.25000</td>\n      <td>23223.000000</td>\n      <td>30.758625</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.610000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>25645.50000</td>\n      <td>56430.500000</td>\n      <td>85.053000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>9.240000</td>\n      <td>7.790000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>38467.75000</td>\n      <td>90008.000000</td>\n      <td>251.053200</td>\n      <td>5.000000</td>\n      <td>0.200000</td>\n      <td>36.810000</td>\n      <td>24.450000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>51290.00000</td>\n      <td>99301.000000</td>\n      <td>22638.480000</td>\n      <td>14.000000</td>\n      <td>0.850000</td>\n      <td>8399.976000</td>\n      <td>933.570000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            Row ID   Postal Code         Sales      Quantity      Discount   \ncount  51290.00000   9994.000000  51290.000000  51290.000000  51290.000000  \\\nmean   25645.50000  55190.379428    246.490581      3.476545      0.142908   \nstd    14806.29199  32063.693350    487.565361      2.278766      0.212280   \nmin        1.00000   1040.000000      0.444000      1.000000      0.000000   \n25%    12823.25000  23223.000000     30.758625      2.000000      0.000000   \n50%    25645.50000  56430.500000     85.053000      3.000000      0.000000   \n75%    38467.75000  90008.000000    251.053200      5.000000      0.200000   \nmax    51290.00000  99301.000000  22638.480000     14.000000      0.850000   \n\n             Profit  Shipping Cost  \ncount  51290.000000   51290.000000  \nmean      28.610982      26.375915  \nstd      174.340972      57.296804  \nmin    -6599.978000       0.000000  \n25%        0.000000       2.610000  \n50%        9.240000       7.790000  \n75%       36.810000      24.450000  \nmax     8399.976000     933.570000  "
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order ID</th>\n      <th>Order Date</th>\n      <th>Ship Date</th>\n      <th>Ship Mode</th>\n      <th>Customer ID</th>\n      <th>Customer Name</th>\n      <th>Segment</th>\n      <th>City</th>\n      <th>State</th>\n      <th>Country</th>\n      <th>Market</th>\n      <th>Region</th>\n      <th>Product ID</th>\n      <th>Category</th>\n      <th>Sub-Category</th>\n      <th>Product Name</th>\n      <th>Order Priority</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n      <td>51290</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>25035</td>\n      <td>1430</td>\n      <td>1464</td>\n      <td>4</td>\n      <td>1590</td>\n      <td>795</td>\n      <td>3</td>\n      <td>3636</td>\n      <td>1094</td>\n      <td>147</td>\n      <td>7</td>\n      <td>13</td>\n      <td>10292</td>\n      <td>3</td>\n      <td>17</td>\n      <td>3788</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>CA-2014-100111</td>\n      <td>18-06-2014</td>\n      <td>22-11-2014</td>\n      <td>Standard Class</td>\n      <td>PO-18850</td>\n      <td>Muhammed Yedwab</td>\n      <td>Consumer</td>\n      <td>New York City</td>\n      <td>California</td>\n      <td>United States</td>\n      <td>APAC</td>\n      <td>Central</td>\n      <td>OFF-AR-10003651</td>\n      <td>Office Supplies</td>\n      <td>Binders</td>\n      <td>Staples</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>14</td>\n      <td>135</td>\n      <td>130</td>\n      <td>30775</td>\n      <td>97</td>\n      <td>108</td>\n      <td>26518</td>\n      <td>915</td>\n      <td>2001</td>\n      <td>9994</td>\n      <td>11002</td>\n      <td>11117</td>\n      <td>35</td>\n      <td>31273</td>\n      <td>6152</td>\n      <td>227</td>\n      <td>29433</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              Order ID  Order Date   Ship Date       Ship Mode Customer ID   \ncount            51290       51290       51290           51290       51290  \\\nunique           25035        1430        1464               4        1590   \ntop     CA-2014-100111  18-06-2014  22-11-2014  Standard Class    PO-18850   \nfreq                14         135         130           30775          97   \n\n          Customer Name   Segment           City       State        Country   \ncount             51290     51290          51290       51290          51290  \\\nunique              795         3           3636        1094            147   \ntop     Muhammed Yedwab  Consumer  New York City  California  United States   \nfreq                108     26518            915        2001           9994   \n\n       Market   Region       Product ID         Category Sub-Category   \ncount   51290    51290            51290            51290        51290  \\\nunique      7       13            10292                3           17   \ntop      APAC  Central  OFF-AR-10003651  Office Supplies      Binders   \nfreq    11002    11117               35            31273         6152   \n\n       Product Name Order Priority  \ncount         51290          51290  \nunique         3788              4  \ntop         Staples         Medium  \nfreq            227          29433  "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Row ID             0.0000\nOrder ID           0.0000\nOrder Date         0.0000\nShip Date          0.0000\nShip Mode          0.0000\nCustomer ID        0.0000\nCustomer Name      0.0000\nSegment            0.0000\nCity               0.0000\nState              0.0000\nCountry            0.0000\nPostal Code       80.5147\nMarket             0.0000\nRegion             0.0000\nProduct ID         0.0000\nCategory           0.0000\nSub-Category       0.0000\nProduct Name       0.0000\nSales              0.0000\nQuantity           0.0000\nDiscount           0.0000\nProfit             0.0000\nShipping Cost      0.0000\nOrder Priority     0.0000\ndtype: float64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isna().sum() * 100 / len(df),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando valores nulos\r\n",
    "# Apagando colunas com mais de 40% de valores nulos\r\n",
    "df.drop('Postal Code', axis=1, inplace = True)\r\n",
    "\r\n",
    "# Excluindo coluna irrelevante\r\n",
    "df.drop('Row ID', axis=1, inplace = True)\r\n",
    "df.drop('Order ID', axis=1, inplace = True)\r\n",
    "df.drop('Customer ID', axis=1, inplace = True)\r\n",
    "df.drop('Product ID', axis=1, inplace = True)\r\n",
    "\r\n",
    "# Substituindo valores nulos pela média (colunas numéricas) ou pela moda (colunas categóricas)\r\n",
    "for column in df.columns:\r\n",
    "    if df[column].dtype == 'object':\r\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\r\n",
    "    else:\r\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\r\n",
    "\r\n",
    "# Preparando os dados\r\n",
    "features = df.drop('Quantity', axis=1) # X\r\n",
    "target = df[['Quantity']] # y\r\n",
    "\r\n",
    "# Convertendo categorias em variáveis numéricas\r\n",
    "label_encoder = LabelEncoder()\r\n",
    "for column in features.columns:\r\n",
    "    if features[column].dtype == 'object':\r\n",
    "        features[column] = label_encoder.fit_transform(features[column])\r\n",
    "\r\n",
    "# Criando os normalizadores\r\n",
    "normalizador_features = MinMaxScaler()\r\n",
    "normalizador_target = MinMaxScaler()\r\n",
    "\r\n",
    "# Normalizando as features\r\n",
    "features = normalizador_features.fit_transform(features)\r\n",
    "\r\n",
    "# Normalizando o target\r\n",
    "target = normalizador_target.fit_transform(target)\r\n",
    "\r\n",
    "# Dividindo os dados em conjuntos de treinamento, validação e teste\r\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\r\n",
    "features_train, features_val, target_train, target_val = train_test_split(features_train, target_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
      "Epoch 2/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 3/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 4/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\n",
      "Epoch 5/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0239 - val_mean_squared_error: 0.0239\n",
      "Epoch 6/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
      "Epoch 7/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 8/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "Epoch 9/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
      "Epoch 10/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "Epoch 11/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
      "Epoch 12/50\n",
      "962/962 [==============================] - 1s 2ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 13/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "Epoch 14/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 15/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 16/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 17/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "Epoch 18/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
      "Epoch 19/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 20/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 21/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "Epoch 22/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
      "Epoch 23/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 24/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 25/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "Epoch 26/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
      "Epoch 27/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 28/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 29/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 30/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
      "Epoch 31/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 32/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 33/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 34/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 35/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 36/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 37/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 38/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "Epoch 39/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 40/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 41/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 42/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 43/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 44/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0185 - val_mean_squared_error: 0.0185\n",
      "Epoch 45/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 46/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 47/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "Epoch 48/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 49/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 50/50\n",
      "962/962 [==============================] - 2s 2ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1ba26da9fd0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Definindo o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=features_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
    "\n",
    "# Definindo o critério de parada antecipada\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(features_train, target_train, validation_data=(features_val, target_val), epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 937us/step\n",
      "Mean Squared Error: 3.0303054737833706\n",
      "R2 Score: 0.41346449648676087\n",
      "Adjusted R2 Score: 0.4124333763516659\n"
     ]
    }
   ],
   "source": [
    "# Testando o modelo\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "# Revertendo a escala das previsões\n",
    "predictions = normalizador_target.inverse_transform(predictions)\n",
    "\n",
    "# Revertendo a escala do target de teste\n",
    "target_test = normalizador_target.inverse_transform(target_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(target_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Calculando R2 e R2 ajustado\n",
    "r2 = r2_score(target_test, predictions)\n",
    "print(f'R2 Score: {r2}')\n",
    "\n",
    "# Função para calcular o R2 ajustado\n",
    "def adjusted_r2(r2, n, p):\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "\n",
    "n = features_test.shape[0]\n",
    "p = features_test.shape[1]\n",
    "adj_r2 = adjusted_r2(r2, n, p)\n",
    "print(f'Adjusted R2 Score: {adj_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Entrega\n",
    "# Nesta fase, normalmente forneceríamos o modelo para os usuários finais e os treinaríamos sobre como usá-lo. \n",
    "# No entanto, essa parte é difícil de demonstrar em um script Python.\n",
    "\n",
    "# 6. Manutenção\n",
    "# Em um projeto de BI real, esta fase envolveria monitorar o desempenho do modelo ao longo do tempo e fazer ajustes conforme necessário. \n",
    "# Isso também é difícil de demonstrar em um script Python, mas é uma parte importante do processo de BI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Resumo e Perguntas\n",
    "\n",
    "Hoje aprendemos sobre a importância do BI e do ciclo analítico de inteligência de dados. Também exploramos as fases de um projeto de BI, desde a estratégia inicial até a manutenção contínua.\n",
    "\n",
    "Algumas perguntas para reflexão:\n",
    "\n",
    "1. Por que é importante definir claramente os objetivos e metas na estratégia de BI?\n",
    "2. Como a análise de requisitos pode impactar o sucesso de um projeto de BI?\n",
    "3. Por que a fase de manutenção é crucial em um projeto de BI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "É importante garantir que os objetivos do projeto estejam alinhados com as necessidades dos usuários para uma estratégia de BI eficaz.\n",
      "\n",
      "Uma análise de requisitos completa e precisa é essencial para garantir que o projeto de BI atenda às necessidades dos usuários.\n",
      "\n",
      "A fase de manutenção em um projeto de BI é crucial para monitorar e atualizar o sistema, garantindo que continue atendendo às necessidades em constante mudança.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemplo: Importância de definir claramente os objetivos e metas na estratégia de BI\n",
    "def importance_of_bi_strategy(objectives, user_needs):\n",
    "    # Verificar se os objetivos do projeto estão alinhados com as necessidades dos usuários\n",
    "    if objectives.equals(user_needs):\n",
    "        print(\"Uma estratégia de BI claramente definida ajuda a garantir que os objetivos do projeto atendam às necessidades dos usuários.\\n\")\n",
    "    else:\n",
    "        print(\"É importante garantir que os objetivos do projeto estejam alinhados com as necessidades dos usuários para uma estratégia de BI eficaz.\\n\")\n",
    "\n",
    "# Exemplo: Impacto da análise de requisitos no sucesso do projeto de BI\n",
    "def impact_of_requirements_analysis(requirements):\n",
    "    # Verificar se todos os requisitos foram identificados e analisados adequadamente\n",
    "    if not requirements.empty:\n",
    "        print(\"Uma análise de requisitos completa e precisa é essencial para garantir que o projeto de BI atenda às necessidades dos usuários.\\n\")\n",
    "    else:\n",
    "        print(\"Certifique-se de identificar e analisar adequadamente todos os requisitos para um projeto de BI bem-sucedido.\\n\")\n",
    "\n",
    "# Exemplo: Importância da fase de manutenção em um projeto de BI\n",
    "def importance_of_maintenance(project_success):\n",
    "    # Verificar se a fase de manutenção é crucial para manter o sucesso do projeto de BI\n",
    "    if not project_success.empty:\n",
    "        print(\"A fase de manutenção em um projeto de BI é crucial para monitorar e atualizar o sistema, garantindo que continue atendendo às necessidades em constante mudança.\\n\")\n",
    "    else:\n",
    "        print(\"Se a fase de manutenção for negligenciada, o sistema de BI pode se tornar obsoleto e não entregar os resultados esperados.\\n\")\n",
    "\n",
    "# Chamada das funções com base na base de dados\n",
    "importance_of_bi_strategy(df['Sales'], df['Order Priority'])\n",
    "impact_of_requirements_analysis(df['Sales'])\n",
    "importance_of_maintenance(df['Profit'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Introdução ao Ciclo Analítico da Inteligência de Dados\n",
    "\n",
    "O Ciclo Analítico da Inteligência de Dados é um processo iterativo que nos permite transformar dados brutos em insights significativos para tomada de decisões. Ele consiste em sete etapas principais:\n",
    "\n",
    "1. **Definição do problema:** Onde identificamos a questão de negócios que queremos resolver.\n",
    "2. **Preparação de dados:** Aqui, coletamos, limpamos e formatamos os dados necessários para nossa análise.\n",
    "3. **Análise exploratória de dados (EDA):** Nesta fase, examinamos os dados para identificar padrões, detectar anomalias e formular hipóteses.\n",
    "4. **Modelagem de dados:** Aqui, criamos modelos matemáticos ou estatísticos para testar nossas hipóteses.\n",
    "5. **Validação:** Nesta etapa, verificamos a precisão de nossos modelos e ajustamos conforme necessário.\n",
    "6. **Implementação:** Aqui, aplicamos nossos modelos validados ao ambiente de produção.\n",
    "7. **Comunicação:** Nesta fase, compartilhamos nossos resultados e insights com as partes interessadas.\n",
    "\n",
    "Vamos explorar cada uma dessas fases com mais detalhes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Aprofundando no Ciclo Analítico da Inteligência de Dados\n",
    "\n",
    "Agora que temos uma visão geral do Ciclo Analítico, vamos explorar cada uma das fases com mais profundidade.\n",
    "\n",
    "1. **Definição do problema:** Esta é talvez a etapa mais crucial do ciclo. Uma definição de problema clara e precisa nos ajuda a direcionar nossos esforços de coleta de dados e análise. Precisamos entender o contexto do negócio e as necessidades das partes interessadas.\n",
    "\n",
    "2. **Preparação de dados:** Os dados brutos raramente estão em um formato que possamos usar diretamente para análise. Eles podem precisar ser limpos, transformados ou agregados de alguma forma. Esta etapa pode incluir tarefas como lidar com valores ausentes, remover outliers e normalizar os dados.\n",
    "\n",
    "3. **Análise exploratória de dados (EDA):** Nesta fase, visualizamos os dados e calculamos estatísticas resumidas para entender os padrões nos dados. Isso nos ajuda a construir intuições sobre os dados e formular hipóteses para testar na próxima etapa.\n",
    "\n",
    "4. **Modelagem de dados:** Aqui, criamos modelos estatísticos ou de aprendizado de máquina para testar nossas hipóteses. O tipo de modelo que escolhemos dependerá do nosso problema e dos dados disponíveis.\n",
    "\n",
    "5. **Validação:** Nesta etapa, avaliamos a qualidade de nossos modelos. Isso pode envolver a divisão dos dados em conjuntos de treinamento e teste, a aplicação do modelo ao conjunto de teste e a comparação das previsões do modelo com os resultados reais.\n",
    "\n",
    "6. **Implementação:** Uma vez que estamos satisfeitos com a qualidade de nossos modelos, podemos implementá-los em um ambiente de produção. Isso pode envolver a escrita de código para automatizar o processo de coleta de dados, análise e relatórios.\n",
    "\n",
    "7. **Comunicação:** Por fim, comunicamos nossos resultados às partes interessadas. Isso pode incluir a criação de relatórios, dashboards ou apresentações, e deve sempre incluir interpretações claras e acionáveis dos resultados.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Resumo e Perguntas\n",
    "\n",
    "Nesta seção, recapitulamos os pontos importantes cobertos na aula. No contexto do ciclo analítico da inteligência de dados, podemos reiterar as fases e a importância de cada uma delas, bem como como elas se encaixam no projeto de BI como um todo. Podemos também revisitar quaisquer conceitos teóricos que tenham sido particularmente importantes.\n",
    "\n",
    "Perguntas de reflexão podem ser apresentadas para incentivar os alunos a pensar mais profundamente sobre o material. Por exemplo:\n",
    "\n",
    "1. Como cada fase do ciclo analítico contribui para a eficácia geral de um projeto de BI?\n",
    "2. Pode existir um projeto de BI bem-sucedido sem uma ou mais dessas fases?\n",
    "3. Como a fase de implementação pode variar dependendo do ambiente de TI de uma organização?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Revisão dos Conceitos\n",
    "\n",
    "## Business Intelligence (BI)\n",
    "\n",
    "- Business Intelligence é o processo de transformação de dados brutos em informações significativas para análise de negócios.\n",
    "\n",
    "## Fases do Projeto de BI\n",
    "\n",
    "1. **Estratégia de BI:** Definir a visão e os objetivos do projeto.\n",
    "2. **Análise de requisitos:** Identificar as necessidades da empresa e dos usuários finais.\n",
    "3. **Design de solução:** Projetar a solução que atenderá aos requisitos identificados.\n",
    "4. **Implementação:** Desenvolver e testar a solução.\n",
    "5. **Entrega:** Lançar a solução para os usuários finais.\n",
    "6. **Manutenção:** Fornecer suporte contínuo e atualizações para a solução.\n",
    "\n",
    "## O Ciclo Analítico da Inteligência de Dados\n",
    "\n",
    "1. **Definição do problema:** Identificar o problema a ser resolvido.\n",
    "2. **Preparação de dados:** Coletar e preparar os dados para análise.\n",
    "3. **Análise exploratória:** Analisar os dados para obter insights e identificar padrões.\n",
    "4. **Modelagem de dados:** Criar um modelo que represente os padrões nos dados.\n",
    "5. **Validação:** Verificar a precisão do modelo.\n",
    "6. **Implementação:** Implementar o modelo na prática.\n",
    "7. **Comunicação:** Comunicar os resultados da análise.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição do problema:\n",
    "A empresa Superstore possui uma base de dados contendo informações de vendas de seus produtos entre 2011 e 2015. Eles estão buscando insights para otimizar suas vendas e melhorar sua lucratividade. Sua tarefa é realizar uma análise e propor soluções para os seguintes questionamentos:\n",
    "\n",
    "Pode usar \"df['Order Date'] = pd.to_datetime(df['Order Date'])\" para conveter colunas com datas para o tipo de dados de datas.\n",
    "\n",
    "1 - Qual a categoria de produto mais vendida durante todo o período?\n",
    "\n",
    "2 - Qual a categoria de produto mais vendida cada ano?\n",
    "\n",
    "3 - Qual a categoria de produto mais vendida no mese de dezembro de cada ano?\n",
    "\n",
    "4 - Qual a região que apresentou maior lucratividade média?\n",
    "\n",
    "5 - Existe alguma relação entre a quantidade vendida e o desconto aplicado?\n",
    "\n",
    "7 - Qual a média da quantidade de compras dos produtos com 50% (0.5) ou mais de desconto?\n",
    "\n",
    "8 - Qual a moda da quantidade de compras dos produtos com 50% (0.5) ou mais de desconto?\n",
    "\n",
    "9 - Preparação de dados:\n",
    "\n",
    "    9.1 - Verificar e tratar valores nulos, se necessário.\n",
    "\n",
    "    9.2 - Selecionar as colunas relevantes para a análise.\n",
    "\n",
    "\n",
    "10 - Análise exploratória de dados:\n",
    "\n",
    "    10.1 - Calcular as vendas totais por categoria de produto.\n",
    "    10.2 - Visualizar as vendas por categoria em um gráfico de barras.\n",
    "    10.3 - Modelagem de dados:\n",
    "\n",
    "11 - Realizar uma regressão linear para analisar a relação entre a quantidade vendida e o desconto aplicado (o X será apenas a coluna \"Discount\" e o y \"Quantity\"). (normalize os dados e separe em treinamento 70%, validação 15% e teste 15%)\n",
    "\n",
    "\n",
    "12 - Avaliar a qualidade do modelo de regressão, utilizando métricas como o erro quadrático médio (MSE) e o coeficiente de determinação (R^2). (Não esqueça de desnormalizar o y de teste e o y predict andes verificar as métricas)\n",
    "\n",
    "\n",
    "13 - Aplique Redução de Dimensionalidade com PCA para reduzir as colunas de X para apenas 3 Colunas (material sobre isto na aula 5, a partir do tópico 2.4)\n",
    "\n",
    "14 - Realize o tratamento dos dados reduzidos para separar em X e y (Precisa normalizar?)\n",
    "\n",
    "15 - Crie uma rede neural com a seguinte estrutura:\n",
    "- camada de entrada\n",
    "- camada oculta com 20 neurônios e função de ativação relu\n",
    "- camada oculta com 40 neurônios e função de ativação relu\n",
    "- camada oculta com 40 neurônios e função de ativação relu\n",
    "- camada oculta com 40 neurônios e função de ativação relu\n",
    "- camada oculta com 40 neurônios e função de ativação relu\n",
    "- camada oculta com 40 neurônios e função de ativação relu\n",
    "- camada oculta com 40 neurônios e função de ativação relu\n",
    "- camada de saída com 1 neurônio e função de ativação linear\n",
    "\n",
    "- Defina para a rede treinar 100 épocas, mas parar o treinamento caso fique 30 épocas sem melhorar a métrica MSE de validação\n",
    "\n",
    "16 - Exiba o gráfico de loss durante o treinamento (esqueceu de fazer o history no fit? rsrs)\n",
    "\n",
    "17 - Exiba as métricas de MSE, MAE, R2 e R2 ajustado.\n",
    "\n",
    "18 - Seu modelo ficou bom?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('superstore_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Office Supplies'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - Qual a categoria de produto mais vendida durante todo o período?\r\n",
    "df['Category'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2011, 2012, 2013, 2014])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 - Qual a categoria de produto mais vendida cada ano?\r\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format = \"mixed\")\r\n",
    "df['Order Date'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2011, 2012, 2013, 2014])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Order Date'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011: Office Supplies\n",
      "2012: Office Supplies\n",
      "2013: Office Supplies\n",
      "2014: Office Supplies\n"
     ]
    }
   ],
   "source": [
    "print('2011:', df.loc[(df['Order Date'].dt.year == 2011), 'Category'].mode()[0])\r\n",
    "print('2012:', df.loc[(df['Order Date'].dt.year == 2012), 'Category'].mode()[0])\r\n",
    "print('2013:', df.loc[(df['Order Date'].dt.year == 2013), 'Category'].mode()[0])\r\n",
    "print('2014:', df.loc[(df['Order Date'].dt.year == 2014), 'Category'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dezembro de 2011: Office Supplies\n",
      "Dezembro de 2012: Office Supplies\n",
      "Dezembro de 2013: Office Supplies\n",
      "Dezembro de 2014: Office Supplies\n"
     ]
    }
   ],
   "source": [
    "# 3 - Qual a categoria de produto mais vendida no mese de dezembro de cada ano?\r\n",
    "print('Dezembro de 2011:', df.loc[(df['Order Date'].dt.month == 12) & (df['Order Date'].dt.year == 2011), 'Category'].mode()[0])\r\n",
    "print('Dezembro de 2012:', df.loc[(df['Order Date'].dt.month == 12) & (df['Order Date'].dt.year == 2012), 'Category'].mode()[0])\r\n",
    "print('Dezembro de 2013:', df.loc[(df['Order Date'].dt.month == 12) & (df['Order Date'].dt.year == 2013), 'Category'].mode()[0])\r\n",
    "print('Dezembro de 2014:', df.loc[(df['Order Date'].dt.month == 12) & (df['Order Date'].dt.year == 2014), 'Category'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Africa', 'Oceania', 'EMEA', 'North', 'Central Asia', 'West',\n       'North Asia', 'Central', 'South', 'Canada', 'Southeast Asia',\n       'East', 'Caribbean'], dtype=object)"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 - Qual a região que apresentou maior lucratividade média?\r\n",
    "df['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa: 19.374674296926095\n",
      "Oceania: 34.43909148264984\n",
      "EMEA: 8.728966196062837\n",
      "North: 40.6683286353187\n",
      "Central Asia: 64.68759130859375\n",
      "West: 33.84903181392445\n",
      "North Asia: 70.82053934987168\n",
      "Central: 28.011512246109564\n",
      "South: 21.122011464258836\n",
      "Canada: 46.399453125\n",
      "Southeast Asia: 5.705442313838287\n",
      "East: 32.13580758426966\n",
      "Caribbean: 20.45640298224852\n"
     ]
    }
   ],
   "source": [
    "for i in df['Region'].unique():\r\n",
    "    print(i + ':', df.loc[(df['Region'] == i), 'Profit'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Asia\n",
      "70.82053934987168\n"
     ]
    }
   ],
   "source": [
    "list = []\r\n",
    "list_ = []\r\n",
    "for i in df['Region'].unique():\r\n",
    "    list_.append(i)\r\n",
    "    list.append(df.loc[(df['Region'] == i), 'Profit'].mean())\r\n",
    "\r\n",
    "print(list_[list.index(max(list))])\r\n",
    "print(max(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python394jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}